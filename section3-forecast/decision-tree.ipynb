{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "In this notebook, we are trying to predict the close price of Monero or XMR cryptocurrency in one day by designing a model using other characteristics of this currency in the previous day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the all subsets of a set for implement exhaustive feature selection\n",
    "from itertools import chain, combinations\n",
    "\n",
    "# to download data of the cryptocurrency\n",
    "import yfinance as yf\n",
    "\n",
    "# to preprocess the data, make, train and evaluate the model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>147.309662</td>\n",
       "      <td>148.931030</td>\n",
       "      <td>146.437485</td>\n",
       "      <td>148.576935</td>\n",
       "      <td>148.576935</td>\n",
       "      <td>36453347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02</th>\n",
       "      <td>148.582184</td>\n",
       "      <td>149.623535</td>\n",
       "      <td>147.943558</td>\n",
       "      <td>147.943558</td>\n",
       "      <td>147.943558</td>\n",
       "      <td>47050925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>147.933929</td>\n",
       "      <td>149.027832</td>\n",
       "      <td>147.628860</td>\n",
       "      <td>148.487930</td>\n",
       "      <td>148.487930</td>\n",
       "      <td>48662135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>148.466995</td>\n",
       "      <td>152.488983</td>\n",
       "      <td>148.342621</td>\n",
       "      <td>150.743652</td>\n",
       "      <td>150.743652</td>\n",
       "      <td>83915181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>150.790253</td>\n",
       "      <td>155.921738</td>\n",
       "      <td>150.769043</td>\n",
       "      <td>155.921738</td>\n",
       "      <td>155.921738</td>\n",
       "      <td>78049428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-04</th>\n",
       "      <td>147.168442</td>\n",
       "      <td>150.702347</td>\n",
       "      <td>145.940781</td>\n",
       "      <td>150.469055</td>\n",
       "      <td>150.469055</td>\n",
       "      <td>59400400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-05</th>\n",
       "      <td>150.474197</td>\n",
       "      <td>151.328369</td>\n",
       "      <td>148.565491</td>\n",
       "      <td>149.623718</td>\n",
       "      <td>149.623718</td>\n",
       "      <td>55704972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-06</th>\n",
       "      <td>149.623337</td>\n",
       "      <td>152.669296</td>\n",
       "      <td>148.641647</td>\n",
       "      <td>151.992264</td>\n",
       "      <td>151.992264</td>\n",
       "      <td>49535004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-07</th>\n",
       "      <td>151.988235</td>\n",
       "      <td>155.247528</td>\n",
       "      <td>151.100983</td>\n",
       "      <td>155.212143</td>\n",
       "      <td>155.212143</td>\n",
       "      <td>61159796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-08</th>\n",
       "      <td>155.219528</td>\n",
       "      <td>156.482040</td>\n",
       "      <td>153.763336</td>\n",
       "      <td>156.191223</td>\n",
       "      <td>156.191223</td>\n",
       "      <td>59858985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2023-01-01  147.309662  148.931030  146.437485  148.576935  148.576935   \n",
       "2023-01-02  148.582184  149.623535  147.943558  147.943558  147.943558   \n",
       "2023-01-03  147.933929  149.027832  147.628860  148.487930  148.487930   \n",
       "2023-01-04  148.466995  152.488983  148.342621  150.743652  150.743652   \n",
       "2023-01-05  150.790253  155.921738  150.769043  155.921738  155.921738   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2023-10-04  147.168442  150.702347  145.940781  150.469055  150.469055   \n",
       "2023-10-05  150.474197  151.328369  148.565491  149.623718  149.623718   \n",
       "2023-10-06  149.623337  152.669296  148.641647  151.992264  151.992264   \n",
       "2023-10-07  151.988235  155.247528  151.100983  155.212143  155.212143   \n",
       "2023-10-08  155.219528  156.482040  153.763336  156.191223  156.191223   \n",
       "\n",
       "              Volume  \n",
       "Date                  \n",
       "2023-01-01  36453347  \n",
       "2023-01-02  47050925  \n",
       "2023-01-03  48662135  \n",
       "2023-01-04  83915181  \n",
       "2023-01-05  78049428  \n",
       "...              ...  \n",
       "2023-10-04  59400400  \n",
       "2023-10-05  55704972  \n",
       "2023-10-06  49535004  \n",
       "2023-10-07  61159796  \n",
       "2023-10-08  59858985  \n",
       "\n",
       "[281 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download data of the cryptocurrency\n",
    "\n",
    "df_xmr = yf.download(tickers=\"XMR-USD\", period=\"max\", interval=\"1d\", start=\"2023-01-01\", end=\"2023-10-09\")\n",
    "df_xmr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloaded dataset has date indices, so this problem is actually a time series problem. But in this notebook, we intend to solve this problem without considering the nature of its time series and analyze and check the final result obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 281 entries, 2023-01-01 to 2023-10-08\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Open       281 non-null    float64\n",
      " 1   High       281 non-null    float64\n",
      " 2   Low        281 non-null    float64\n",
      " 3   Close      281 non-null    float64\n",
      " 4   Adj Close  281 non-null    float64\n",
      " 5   Volume     281 non-null    int64  \n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 15.4 KB\n"
     ]
    }
   ],
   "source": [
    "df_xmr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_class = (\n",
    "    (df_xmr.loc[\"2023-01-02\":, \"Close\"].to_numpy() > df_xmr.loc[\"2023-01-01\":\"2023-10-07\", \"Close\"]).astype(int)\n",
    ")\n",
    "df_xmr = df_xmr.drop(\"2023-10-08\")\n",
    "df_xmr[\"Price increase (in the next day)\"] = actual_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "We use exhaustive feature selection method. In this method, the performance of all subsets of the set of columns are evaluated and the subset that gives us the best score is selected. In fact, this method, like brute force, checks all possible modes, and returns the mode with the best performance. Here we use the cross validation score to evaluate our model and finally, using the selected features, we get the ``f1_score`` of our model using test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected feature(s): ['Volume']\n",
      "cross validation score of the model: 0.56\n"
     ]
    }
   ],
   "source": [
    "# Define feature columns\n",
    "feature_cols = ['Open', 'High', 'Low', 'Adj Close', 'Volume']\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"\"\"a function for return all subsets of an iterable\n",
    "    (ref: https://stackoverflow.com/questions/1482308/how-to-get-all-subsets-of-a-set-powerset)\n",
    "\n",
    "    Args:\n",
    "        iterable: collection of some data\n",
    "\n",
    "    Returns:\n",
    "        all subsets of the iterable\n",
    "    \"\"\"\n",
    "    return chain.from_iterable(\n",
    "        combinations(iterable, r) for r in range(len(iterable) + 1)\n",
    "    )\n",
    "\n",
    "\n",
    "# feature selection using exhaustively feature selection\n",
    "# we use cross validation method to select the best features\n",
    "max_cv_score = 0  # the maximum cross validation score\n",
    "selected_features = None  # the best features\n",
    "for features in list(powerset(feature_cols))[\n",
    "    1:\n",
    "]:\n",
    "    # select the required feature(s) and label\n",
    "    X = df_xmr.loc[:\"2023-09-07\", list(features)]  # feature(s)\n",
    "    y = df_xmr.loc[:\"2023-09-07\", \"Price increase (in the next day)\"]  # target\n",
    "\n",
    "    # scaling the values of the features with StandardScaler\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # create random forest model\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # calculate score of the model for train set using cross validation method\n",
    "    # ref: https://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "    # store the best result\n",
    "    if cv_scores.mean() > max_cv_score:\n",
    "        # update max_cv_score variable\n",
    "        max_cv_score = cv_scores.mean()\n",
    "        # update selected features variable\n",
    "        selected_features = list(features)\n",
    "\n",
    "# print the best features for random forest and maximum cv_score\n",
    "print(\"selected feature(s):\", selected_features)\n",
    "print(\"cross validation score of the model:\", max_cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Train Model with Best Features and Get Results\n",
    "\n",
    "In the following code blocks, we create our model and train it with the data of the best features and classify each day by predicted value of our trained model. Finally, we calculate the accuracy, precision, f1-score, recall and auc score, and also plot the confusion matrix in the last part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split features and target variable for training, validation, and test sets\n",
    "X_train, y_train = df_xmr.loc[:\"2023-09-07\", list(features)], df_xmr.loc[:\"2023-09-07\", 'Price increase (in the next day)']\n",
    "X_test, y_test = df_xmr.loc[\"2023-09-08\":, list(features)], df_xmr.loc[\"2023-09-08\":, 'Price increase (in the next day)']\n",
    "\n",
    "# Train the random forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Performance:\n",
      "Test Accuracy: 0.5333333333333333\n",
      "Test Precision: 0.5909090909090909\n",
      "Test Recall: 0.7222222222222222\n",
      "Test F1 Score: 0.65\n",
      "Test AUC: 0.4861111111111111\n",
      "Test Confusion Matrix: [[ 3  9]\n",
      " [ 5 13]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance on the test set\n",
    "test_accuracy = metrics.accuracy_score(y_test, test_predictions)\n",
    "test_precision = metrics.precision_score(y_test, test_predictions)\n",
    "test_recall = metrics.recall_score(y_test, test_predictions)\n",
    "test_f1 = metrics.f1_score(y_test, test_predictions)\n",
    "test_auc = metrics.roc_auc_score(y_test, test_predictions)\n",
    "test_confusion = metrics.confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "# Print evaluation metrics and confusion matrix for the test set\n",
    "print('\\nTest Set Performance:')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print(f'Test Precision: {test_precision}')\n",
    "print(f'Test Recall: {test_recall}')\n",
    "print(f'Test F1 Score: {test_f1}')\n",
    "print(f'Test AUC: {test_auc}')\n",
    "print(f'Test Confusion Matrix: {test_confusion}')\n",
    "\n",
    "# cm_display = metrics.ConfusionMatrixDisplay(\n",
    "#     confusion_matrix=metrics.confusion_matrix, display_labels=[False, True]\n",
    "# )\n",
    "# cm_display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
