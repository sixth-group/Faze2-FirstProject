{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the all subsets of a set for implement exhaustive feature selection\n",
    "from itertools import chain, combinations\n",
    "\n",
    "# to read and manipulation data\n",
    "import pandas as pd\n",
    "\n",
    "# to download data of the cryptocurrency\n",
    "import yfinance as yf\n",
    "\n",
    "# to preprocess the data, make, train and evaluate the model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# download data of the cryptocurrency\n",
    "\n",
    "df_xmr = yf.download(tickers=\"XMR-USD\", period=\"max\", interval=\"1d\", start=\"2023-01-01\", end=\"2023-10-09\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>147.309662</td>\n",
       "      <td>148.931030</td>\n",
       "      <td>146.437485</td>\n",
       "      <td>148.576935</td>\n",
       "      <td>148.576935</td>\n",
       "      <td>36453347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02</th>\n",
       "      <td>148.582184</td>\n",
       "      <td>149.623535</td>\n",
       "      <td>147.943558</td>\n",
       "      <td>147.943558</td>\n",
       "      <td>147.943558</td>\n",
       "      <td>47050925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>147.933929</td>\n",
       "      <td>149.027832</td>\n",
       "      <td>147.628860</td>\n",
       "      <td>148.487930</td>\n",
       "      <td>148.487930</td>\n",
       "      <td>48662135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>148.466995</td>\n",
       "      <td>152.488983</td>\n",
       "      <td>148.342621</td>\n",
       "      <td>150.743652</td>\n",
       "      <td>150.743652</td>\n",
       "      <td>83915181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>150.790253</td>\n",
       "      <td>155.921738</td>\n",
       "      <td>150.769043</td>\n",
       "      <td>155.921738</td>\n",
       "      <td>155.921738</td>\n",
       "      <td>78049428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2023-01-01  147.309662  148.931030  146.437485  148.576935  148.576935   \n",
       "2023-01-02  148.582184  149.623535  147.943558  147.943558  147.943558   \n",
       "2023-01-03  147.933929  149.027832  147.628860  148.487930  148.487930   \n",
       "2023-01-04  148.466995  152.488983  148.342621  150.743652  150.743652   \n",
       "2023-01-05  150.790253  155.921738  150.769043  155.921738  155.921738   \n",
       "\n",
       "              Volume  \n",
       "Date                  \n",
       "2023-01-01  36453347  \n",
       "2023-01-02  47050925  \n",
       "2023-01-03  48662135  \n",
       "2023-01-04  83915181  \n",
       "2023-01-05  78049428  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the downloaded data\n",
    "df_xmr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_class = (\n",
    "    (df_xmr.loc[\"2023-01-04\":, \"Close\"].to_numpy() > df_xmr.loc[\"2023-01-03\":\"2023-10-07\", \"Close\"]).astype(int)\n",
    ")\n",
    "df_xmr = df_xmr.drop(\"2023-10-08\")\n",
    "df_xmr[\"Price increase (in the next day)\"] = actual_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 7s 262ms/step - loss: 0.9182 - accuracy: 0.4916 - val_loss: 0.6934 - val_accuracy: 0.5111\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.9319 - accuracy: 0.4693 - val_loss: 0.6939 - val_accuracy: 0.5111\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8634 - accuracy: 0.4804 - val_loss: 0.6943 - val_accuracy: 0.5111\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.8295 - accuracy: 0.4693 - val_loss: 0.6943 - val_accuracy: 0.5111\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7941 - accuracy: 0.5531 - val_loss: 0.6942 - val_accuracy: 0.5111\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7770 - accuracy: 0.5307 - val_loss: 0.6942 - val_accuracy: 0.5111\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7856 - accuracy: 0.5419 - val_loss: 0.6941 - val_accuracy: 0.5111\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7766 - accuracy: 0.5140 - val_loss: 0.6943 - val_accuracy: 0.5111\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7596 - accuracy: 0.4637 - val_loss: 0.6941 - val_accuracy: 0.5111\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7711 - accuracy: 0.5084 - val_loss: 0.6942 - val_accuracy: 0.5111\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7129 - accuracy: 0.5754 - val_loss: 0.6939 - val_accuracy: 0.5111\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7775 - accuracy: 0.5251 - val_loss: 0.6942 - val_accuracy: 0.5111\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8112 - accuracy: 0.4246 - val_loss: 0.6947 - val_accuracy: 0.5111\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7723 - accuracy: 0.5307 - val_loss: 0.6949 - val_accuracy: 0.5111\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7406 - accuracy: 0.5251 - val_loss: 0.6957 - val_accuracy: 0.5111\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7758 - accuracy: 0.4749 - val_loss: 0.6965 - val_accuracy: 0.5111\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7174 - accuracy: 0.5754 - val_loss: 0.6963 - val_accuracy: 0.5111\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7490 - accuracy: 0.5475 - val_loss: 0.6959 - val_accuracy: 0.5111\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7639 - accuracy: 0.4972 - val_loss: 0.6959 - val_accuracy: 0.5111\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7075 - accuracy: 0.5419 - val_loss: 0.6954 - val_accuracy: 0.5111\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7709 - accuracy: 0.5084 - val_loss: 0.6951 - val_accuracy: 0.5111\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7820 - accuracy: 0.4693 - val_loss: 0.6953 - val_accuracy: 0.5111\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6902 - accuracy: 0.5363 - val_loss: 0.6956 - val_accuracy: 0.5111\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7442 - accuracy: 0.4804 - val_loss: 0.6962 - val_accuracy: 0.5111\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8108 - accuracy: 0.4749 - val_loss: 0.6960 - val_accuracy: 0.5111\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7463 - accuracy: 0.5307 - val_loss: 0.6954 - val_accuracy: 0.5111\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7382 - accuracy: 0.5419 - val_loss: 0.6950 - val_accuracy: 0.5111\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7661 - accuracy: 0.4860 - val_loss: 0.6952 - val_accuracy: 0.5111\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7523 - accuracy: 0.5363 - val_loss: 0.6954 - val_accuracy: 0.5111\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7184 - accuracy: 0.5531 - val_loss: 0.6958 - val_accuracy: 0.5111\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7017 - accuracy: 0.5531 - val_loss: 0.6960 - val_accuracy: 0.5111\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7522 - accuracy: 0.5363 - val_loss: 0.6959 - val_accuracy: 0.5111\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7209 - accuracy: 0.5587 - val_loss: 0.6960 - val_accuracy: 0.5111\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7530 - accuracy: 0.5028 - val_loss: 0.6957 - val_accuracy: 0.5111\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7495 - accuracy: 0.5251 - val_loss: 0.6958 - val_accuracy: 0.5111\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7702 - accuracy: 0.4693 - val_loss: 0.6955 - val_accuracy: 0.5111\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7372 - accuracy: 0.5140 - val_loss: 0.6950 - val_accuracy: 0.5111\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7475 - accuracy: 0.4860 - val_loss: 0.6947 - val_accuracy: 0.5111\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7624 - accuracy: 0.4693 - val_loss: 0.6948 - val_accuracy: 0.5111\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7975 - accuracy: 0.4302 - val_loss: 0.6953 - val_accuracy: 0.5111\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7081 - accuracy: 0.5196 - val_loss: 0.6954 - val_accuracy: 0.5111\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7784 - accuracy: 0.5196 - val_loss: 0.6958 - val_accuracy: 0.5111\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7046 - accuracy: 0.5866 - val_loss: 0.6960 - val_accuracy: 0.5111\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7189 - accuracy: 0.5196 - val_loss: 0.6959 - val_accuracy: 0.5111\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7468 - accuracy: 0.4413 - val_loss: 0.6962 - val_accuracy: 0.5111\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7647 - accuracy: 0.5084 - val_loss: 0.6963 - val_accuracy: 0.5111\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7401 - accuracy: 0.5251 - val_loss: 0.6960 - val_accuracy: 0.5111\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7076 - accuracy: 0.5419 - val_loss: 0.6962 - val_accuracy: 0.5111\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7147 - accuracy: 0.5251 - val_loss: 0.6958 - val_accuracy: 0.5111\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7166 - accuracy: 0.4637 - val_loss: 0.6957 - val_accuracy: 0.5111\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7406 - accuracy: 0.4972 - val_loss: 0.6957 - val_accuracy: 0.5111\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7449 - accuracy: 0.5084 - val_loss: 0.6962 - val_accuracy: 0.5111\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7414 - accuracy: 0.4916 - val_loss: 0.6967 - val_accuracy: 0.5111\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7300 - accuracy: 0.5140 - val_loss: 0.6970 - val_accuracy: 0.5111\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7423 - accuracy: 0.4972 - val_loss: 0.6968 - val_accuracy: 0.5111\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7021 - accuracy: 0.5419 - val_loss: 0.6968 - val_accuracy: 0.5111\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7085 - accuracy: 0.5251 - val_loss: 0.6967 - val_accuracy: 0.5111\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6943 - accuracy: 0.6201 - val_loss: 0.6970 - val_accuracy: 0.5111\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7586 - accuracy: 0.5028 - val_loss: 0.6969 - val_accuracy: 0.5111\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7359 - accuracy: 0.4860 - val_loss: 0.6963 - val_accuracy: 0.5111\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7043 - accuracy: 0.5587 - val_loss: 0.6966 - val_accuracy: 0.5111\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7576 - accuracy: 0.4637 - val_loss: 0.6970 - val_accuracy: 0.5111\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7624 - accuracy: 0.4637 - val_loss: 0.6972 - val_accuracy: 0.5111\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7056 - accuracy: 0.5307 - val_loss: 0.6975 - val_accuracy: 0.5111\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7637 - accuracy: 0.5084 - val_loss: 0.6980 - val_accuracy: 0.5111\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7207 - accuracy: 0.5587 - val_loss: 0.6978 - val_accuracy: 0.5111\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7313 - accuracy: 0.4804 - val_loss: 0.6974 - val_accuracy: 0.5111\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7250 - accuracy: 0.5251 - val_loss: 0.6975 - val_accuracy: 0.5111\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7504 - accuracy: 0.4972 - val_loss: 0.6976 - val_accuracy: 0.5111\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7538 - accuracy: 0.4916 - val_loss: 0.6969 - val_accuracy: 0.5111\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7331 - accuracy: 0.5307 - val_loss: 0.6966 - val_accuracy: 0.5111\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7179 - accuracy: 0.5307 - val_loss: 0.6962 - val_accuracy: 0.5111\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7237 - accuracy: 0.5642 - val_loss: 0.6962 - val_accuracy: 0.5111\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7240 - accuracy: 0.5363 - val_loss: 0.6958 - val_accuracy: 0.5111\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7242 - accuracy: 0.5642 - val_loss: 0.6955 - val_accuracy: 0.5111\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7239 - accuracy: 0.5419 - val_loss: 0.6955 - val_accuracy: 0.5111\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7316 - accuracy: 0.5196 - val_loss: 0.6956 - val_accuracy: 0.5111\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7532 - accuracy: 0.4413 - val_loss: 0.6956 - val_accuracy: 0.5111\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7433 - accuracy: 0.4749 - val_loss: 0.6959 - val_accuracy: 0.5111\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7066 - accuracy: 0.5419 - val_loss: 0.6959 - val_accuracy: 0.5111\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7431 - accuracy: 0.5196 - val_loss: 0.6960 - val_accuracy: 0.5111\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7513 - accuracy: 0.4749 - val_loss: 0.6958 - val_accuracy: 0.5111\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7308 - accuracy: 0.5028 - val_loss: 0.6957 - val_accuracy: 0.5111\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6950 - accuracy: 0.5587 - val_loss: 0.6957 - val_accuracy: 0.5111\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7146 - accuracy: 0.5363 - val_loss: 0.6962 - val_accuracy: 0.5111\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7124 - accuracy: 0.5140 - val_loss: 0.6967 - val_accuracy: 0.5111\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7060 - accuracy: 0.5866 - val_loss: 0.6973 - val_accuracy: 0.5111\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7444 - accuracy: 0.5140 - val_loss: 0.6981 - val_accuracy: 0.5111\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7346 - accuracy: 0.4693 - val_loss: 0.6983 - val_accuracy: 0.5111\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7148 - accuracy: 0.5363 - val_loss: 0.6979 - val_accuracy: 0.5111\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6988 - accuracy: 0.5531 - val_loss: 0.6976 - val_accuracy: 0.5111\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7109 - accuracy: 0.5251 - val_loss: 0.6975 - val_accuracy: 0.5111\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7288 - accuracy: 0.5028 - val_loss: 0.6974 - val_accuracy: 0.5111\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6971 - accuracy: 0.5140 - val_loss: 0.6972 - val_accuracy: 0.5111\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7086 - accuracy: 0.5475 - val_loss: 0.6973 - val_accuracy: 0.5111\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7270 - accuracy: 0.4972 - val_loss: 0.6969 - val_accuracy: 0.5111\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7099 - accuracy: 0.5642 - val_loss: 0.6965 - val_accuracy: 0.5111\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.7004 - accuracy: 0.5307 - val_loss: 0.6961 - val_accuracy: 0.5111\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7140 - accuracy: 0.5140 - val_loss: 0.6961 - val_accuracy: 0.5111\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6902 - accuracy: 0.5419 - val_loss: 0.6964 - val_accuracy: 0.5111\n",
      "2/2 [==============================] - 1s 4ms/step\n",
      "Accuracy: 0.5111111111111111\n",
      "Precision: 0.5111111111111111\n",
      "Recall: 1.0\n",
      "F1 Score: 0.676470588235294\n",
      "AUC: 0.4782608695652174\n",
      "Confusion Matrix:\n",
      "[[ 0 22]\n",
      " [ 0 23]]\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "\n",
      "Test Set Performance:\n",
      "Test Accuracy: 0.5892857142857143\n",
      "Test Precision: 0.5892857142857143\n",
      "Test Recall: 1.0\n",
      "Test F1 Score: 0.7415730337078651\n",
      "Test AUC: 0.5\n",
      "Test Confusion Matrix:\n",
      "[[ 0 23]\n",
      " [ 0 33]]\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "train_data, test_data = train_test_split(df_xmr, test_size=0.2, shuffle=False)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Define feature columns and target variable\n",
    "feature_cols = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "target_col = 'Price increase (in the next day)'\n",
    "\n",
    "# Split features and target variable for training, validation, and test sets\n",
    "X_train, y_train = train_data[feature_cols], train_data[target_col]\n",
    "X_val, y_val = val_data[feature_cols], val_data[target_col]\n",
    "X_test, y_test = test_data[feature_cols], test_data[target_col]\n",
    "\n",
    "# Handle missing values in the features and target variables\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_val = imputer.transform(X_val)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Handle missing values in the target variable\n",
    "imputer_target = SimpleImputer(strategy=\"most_frequent\")\n",
    "y_train = imputer_target.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "y_val = imputer_target.transform(y_val.values.reshape(-1, 1)).ravel()\n",
    "y_test = imputer_target.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Reshape features into 3D format (samples, timesteps, features)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], 1, X_val.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train the LSTM model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_probabilities = model.predict(X_val)\n",
    "val_predictions = (val_probabilities > 0.5).astype(int)\n",
    "\n",
    "# Evaluate model performance on the validation set\n",
    "accuracy = accuracy_score(y_val, val_predictions)\n",
    "precision = precision_score(y_val, val_predictions)\n",
    "recall = recall_score(y_val, val_predictions)\n",
    "f1 = f1_score(y_val, val_predictions)\n",
    "auc = roc_auc_score(y_val, val_probabilities)\n",
    "confusion = confusion_matrix(y_val, val_predictions)\n",
    "\n",
    "# Print evaluation metrics and confusion matrix\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'AUC: {auc}')\n",
    "print('Confusion Matrix:')\n",
    "print(confusion)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_probabilities = model.predict(X_test)\n",
    "test_predictions = (test_probabilities > 0.5).astype(int)\n",
    "\n",
    "# Evaluate model performance on the test set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_precision = precision_score(y_test, test_predictions)\n",
    "test_recall = recall_score(y_test, test_predictions)\n",
    "test_f1 = f1_score(y_test, test_predictions)\n",
    "test_auc = roc_auc_score(y_test, test_probabilities)\n",
    "test_confusion = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "# Print evaluation metrics and confusion matrix for the test set\n",
    "print('\\nTest Set Performance:')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print(f'Test Precision: {test_precision}')\n",
    "print(f'Test Recall: {test_recall}')\n",
    "print(f'Test F1 Score: {test_f1}')\n",
    "print(f'Test AUC: {test_auc}')\n",
    "print('Test Confusion Matrix:')\n",
    "print(test_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Performance:\n",
      "Test Accuracy: 0.5892857142857143\n",
      "Test Precision: 0.5892857142857143\n",
      "Test Recall: 1.0\n",
      "Test F1 Score: 0.7415730337078651\n",
      "Test AUC: 0.5\n",
      "Test Confusion Matrix:\n",
      "[[ 0 23]\n",
      " [ 0 33]]\n"
     ]
    }
   ],
   "source": [
    "# Print evaluation metrics and confusion matrix for the test set\n",
    "print('\\nTest Set Performance:')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print(f'Test Precision: {test_precision}')\n",
    "print(f'Test Recall: {test_recall}')\n",
    "print(f'Test F1 Score: {test_f1}')\n",
    "print(f'Test AUC: {test_auc}')\n",
    "print('Test Confusion Matrix:')\n",
    "print(test_confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
